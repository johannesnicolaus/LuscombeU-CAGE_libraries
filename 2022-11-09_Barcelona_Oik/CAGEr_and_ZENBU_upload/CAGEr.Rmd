---
title: "CAGE Oikopleura"
author: "Charles Plessy"
date: "19/07/2023"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load the CAGE data from BAM files.

BAM files produced by HiSat2 are loaded in paired-end mode.  Sample names are
parsed from the file names.

```{r setup}
BSgenomeToUse <- "BSgenome.Oidioi.OIST.Bar2.p4"
if(isFALSE(requireNamespace(BSgenomeToUse, quietly = TRUE)))
  install.packages(BSgenomeToUse,
                   repos="https://oist.github.io/plessy_oikgenomes_drat/")
pathToBamFiles <- "hisat2"
```

```{r}
library("CAGEr")
library("ggplot2")

pathsToInputFiles <- list.files(pathToBamFiles,
                                pattern = "*.sorted.bam$",
                                full.names = TRUE)
sampleLabels <- make.names(sub( ".sorted.bam", "", basename(pathsToInputFiles)))
ce <-
  CAGEexp( metadata = list(genomeName = BSgenomeToUse)
         , colData  = DataFrame( inputFiles     = pathsToInputFiles
                               , sampleLabels   = sampleLabels
                               , inputFilesType = "bamPairedEnd"
                               , row.names      = sampleLabels))

ce <- getCTSS(ce, useMulticore = TRUE, nrCores = 3, correctSystematicG=FALSE, removeFirstG=FALSE)
```

# Polish sample data

Extra information is parsed from the file names, and is used to prepare short
descriptions in plain English.

```{r}
librarySizes(ce) # This is only the mapped ones
colData(ce)
ce$SLfound  <- grepl("SL", sampleLabels(ce))
ce$SLfactor <- ce$SLfound |> factor(labels = c("SL not found", "SL found"))
ce$sampleType <- "Adult"
ce$sampleType[grepl("Rep", sampleLabels(ce))] <- "Embry"
ce$RNA <- sampleLabels(ce) |> sub(pat = "_SL.*|_no.*", rep = "") |> sub(pat = "^X", rep = "") |> unname()
ce$Description <-
  paste0("Oikopleura dioica (Barcelona) CAGE library prepared by DNAFORM in 2022—23 from the RNA sample “",
       ce$RNA, "”. ",
       ifelse(ce$SLfound, "A splice leader sequence was found and removed. ",
              "No splice leader sequence was found. "),
       "The reads where then aligned with HISAT2 using the nf-core RNA-seq pipeline version 3.4.")

colData(ce)
```

## Get counts of unmapped reads

```{r hisat}
hs <- read.table(head = TRUE, "../AlignWithRNAseqPipelinePE/results/multiqc/hisat2/multiqc_data/multiqc_hisat2.txt")
rownames(hs) <- make.names(hs$Sample)
hs <- hs[sampleLabels(ce),]
# Apparently, multimapped reads have been removed by the pipeline.
all(librarySizes(ce) == hs$paired_aligned_one)
ce$paired_aligned_one   <- hs$paired_aligned_one
ce$paired_aligned_multi <- hs$paired_aligned_multi
ce$paired_total         <- hs$paired_total
```

```{r otherqc}
qc <- read.table(head = TRUE, sep = '\t', "../AlignWithRNAseqPipelinePE/results/multiqc/hisat2/multiqc_data/multiqc_general_stats.txt")
rownames(qc) <- make.names(qc$Sample)
qc2 <- qc[paste0(sampleLabels(ce), "_2"),]
ce$realLibrarySizes <- qc2$FastQC..raw._mqc.generalstats.fastqc_raw.total_sequences
ce$extracted    <- qc2$FastQC..trimmed._mqc.generalstats.fastqc_trimmed.total_sequences
```

```{r rrna}
# Unfortunately we have only the sum of the extraction for both reads,
# But we need the results in number of pairs.
# rrna <- read.table(head = TRUE, sep = '\t', "../AlignWithRNAseqPipelinePE/results/multiqc/hisat2/multiqc_data/multiqc_sortmerna.txt")
# rownames(rrna) <- make.names(rrna$Sample)
# ce$rdna <- rrna[paste0(sampleLabels(ce), "_2"), "rRNA"]

# Good enough approximate:
ce$rdna <- ce$extracted - ce$paired_total
```

### Pipeline QC

 - Almost all reads were properly extracted (non-Discarded).
 - The proportion on unmapped reads is moderate.
 - We do not find rRNA reads in the trans-spliced RNAs.
 - The proportion of trans-spliced reads is noticeably smaller in the male sample.

```{r pipeline_QC}
msScope_nfcore_rnaseq <- function(libs) {
  CAGEr:::.checkLibsDataFrame(libs, c("extracted", "rdna",
                                      "paired_total", "paired_aligned_multi", "paired_aligned_one",
                                      "realLibrarySizes"))
  libs$rDNA           <- libs$rdna
  libs$Unmapped       <- libs$paired_total - libs$paired_aligned_one - libs$paired_aligned_multi
  libs$Multimapped    <- libs$paired_aligned_multi
  libs$UniquelyMapped <- libs$paired_aligned_one
  libs$Discarded      <- libs$realLibrarySizes - libs$extracted
  list(libs = libs, columns = c("Discarded","rDNA", "Unmapped", "Multimapped", "UniquelyMapped"), total = libs$realLibrarySizes)
}
plotAnnot(ce, msScope_nfcore_rnaseq, group = "RNA", facet = "SLfactor", norm = FALSE) +
  ylab("Number of tags processed") + xlab("Sample name") +
  ggtitle("QC report of library alignment")
```

# Annotate

As of January 2023, the gene models were produced by AUGUSTUS, and begin
at the translation start site.  The plots below should therefore be interpreted
with caution.

```{r}
gff <- rtracklayer::import("../AlignWithRNAseqPipelinePE/Bar2_p4.gm.gtf")
gff$type <- as.character(gff$type)
gff <- gff[gff$type %in% c("transcript", "intron", "exon")]
gff$gene_name <- gff$gene_id

ce <- annotateCTSS(ce, gff)
colData(ce)[,c("librarySizes", "promoter", "exon", "intron", "unknown")]
colData(ce)[,c("promoter", "exon", "intron", "unknown")] |> as.matrix() |> prop.table(1)  |> round(2)
plotAnnot(ce, "counts", group = "RNA", facet = "SLfactor", normalise = TRUE) +
  ylab("Fraction of tags aligned") +
  xlab("Sample name") +
  ggtitle("Annotation of the aligned tags")
```

# Correlate expression per chromosome.

This gives a very quick and rough clustering of the samples.

```{r}
ce <- summariseChrExpr(ce)
seqNameTotalsSE(ce) |> assay()
seqNameTotalsSE(ce) |> assay() |> cor(meth="spe") |> pheatmap::pheatmap()
```

# Reverse cumulative distribution of the CTSSes

Distributions of expression values differ strongly between the trans-splicing
sites and the transcription start sites.  We will need to normalise them
separately.


```{r}
ce <- setColors(ce, c("red", "red", "red", "red",
                      "blue", "blue",
                      "pink", "pink", "pink", "pink",
                      "green", "green", "green", "green", "green", "green", "green", "green"))
rangeForSL <- c(1e1, 5e2)
plotReverseCumulatives(ce[,   ce$SLfound], fitInRange = rangeForSL, values = "raw", onePlot = TRUE, main = "SL found")
rangeForTSS <- c(3e1, 3e4)
plotReverseCumulatives(ce[, ! ce$SLfound], fitInRange = rangeForTSS, values = "raw", onePlot = TRUE, main = "SL not found")
```

# Split the objects and normalise

## TPM for the trans-splicing sites

The expression values SL peaks do not follow a power law distribution.

```{r}
ce_SL <- ce[,   ce$SLfound] |>
  resetCAGEexp() |>
  normalizeTagCount(method = "simpleTpm")
plotReverseCumulatives(ce_SL, fitInRange = NULL, values = "normalized", onePlot = TRUE, main = "SL found")
```

The male library has a different distribution of CTSS expression values compared
with others.

## Power law for the transcription start sites.

```{r}
ce_no <- ce[, ! ce$SLfound] |> resetCAGEexp()
rangeForTSS <- c(3e1, 3e4)
plotReverseCumulatives(ce_no, fitInRange = rangeForTSS, values = "raw", onePlot = TRUE, main = "SL not found (raw)")
ce_no |> normalizeTagCount(method = "simpleTpm", fitInRange = rangeForTSS) |>
  plotReverseCumulatives(ce_no.tpm, fitInRange = NULL, values = "normalized", onePlot = TRUE, main = "SL not found (TPM normalisation)")
ce_no <- ce_no |> normalizeTagCount(method = "powerLaw", fitInRange = rangeForTSS)
plotReverseCumulatives(ce_no, fitInRange = NULL, values = "normalized", onePlot = TRUE, main = "SL not found (power law normalisation")
```

The power law normalisation is more efficient at giving the same distribution
to the libraries, at least on average expression values.  Again, the male
library makes an exception.

# Clustering

## Produce sharp clusters of trans-splicing sites

Try different parameters

```{r try_paraclu}
p10.0 <- ce_SL |> CTSSnormalizedTpmGR(1)|> head(10000) |> paraclu(maxLength = 10L, removeSingletons = TRUE, keepSingletonsAbove = 0)
hist(decode(score(p10.0))|>log10())
# The distribution of scores is bimodal, with a valley around 1.
ce_SL |> CTSSnormalizedTpmGR(1)|> head(1000) |> paraclu(maxLength = 10L, removeSingletons = TRUE, keepSingletonsAbove = 1) |> length()
ce_SL |> CTSSnormalizedTpmGR(1)|> head(1000) |> paraclu(maxLength = 20L, removeSingletons = TRUE, keepSingletonsAbove = 1) |> length()
ce_SL |> CTSSnormalizedTpmGR(1)|> head(1000) |> paraclu(maxLength = 50L, removeSingletons = TRUE, keepSingletonsAbove = 1) |> length()
ce_SL |> CTSSnormalizedTpmGR(1)|> head(1000) |> paraclu(maxLength = 200L, removeSingletons = TRUE, keepSingletonsAbove = 1) |> length()
ce_SL |> CTSSnormalizedTpmGR(1)|> head(1000) |> paraclu(maxLength = 500L, removeSingletons = TRUE, keepSingletonsAbove = 1) |> length()
# There is not much penalty keeping the peaks narrow.
```

## Produce sharp clusters of trans-splicing sites

```{r ce_SL_paraclu}
ce_SL <- ce_SL |> clusterCTSS( method = "paraclu"
                             , nrPassThreshold = 1 # Default.  We do not have replicates for all time points
                             , threshold = 1   # See above.  Note that it allows low-score CTSS supported in other samples.
                             , maxLength = 10L # Keep them sharp
                             , useMulticore = TRUE # Deigo
                             , nrCores = 8)    |>    # Yay !
                  cumulativeCTSSdistribution() |>
                  quantilePositions()
plotInterquantileWidth(ce_SL, clusters = "tagClusters", tpmThreshold = 3, qLow = 0.1, qUp = 0.9) + ggplot2::theme_bw()
tagClustersGR(ce_SL) |> sapply(length)
tagClustersGR(ce_SL, 1) |> score() |> decode() |> log10() |> hist(br=100)
tagClustersGR(ce_SL, "X41MA_SL") |> score() |> decode() |> log10() |> hist(br=100) # Males !

(tagClustersGR(ce_SL, 1) |> score() > 1) |> sum()
```

## Cluster clusters of transcription start sites.

  
```{r ce_no_paraclu}
ce_no <- ce_no |> clusterCTSS( method = "distclu"  # Not enough memory for paraclu?  Mabye because running in parallel?
                             , nrPassThreshold = 1 # Default.  We do not have replicates for all time points
                             , threshold = 1   # Default
                            # , maxLength = 200 # Not the default
                             , useMulticore = TRUE # Deigo
                             , nrCores = 8)    |>    # Yay !
                  cumulativeCTSSdistribution() |>
                  quantilePositions()
plotInterquantileWidth(ce_no, clusters = "tagClusters", tpmThreshold = 3, qLow = 0.1, qUp = 0.9) + ggplot2::theme_bw()
```

# Aggregate the CAGE tags


```{r}
ce_SL <- ce_SL |> 
  aggregateTagClusters(maxDist = 10L, tpmThreshold = 1) |>  # See the score distribution
  cumulativeCTSSdistribution(clusters = "consensusClusters") |>
  quantilePositions(clusters = "consensusClusters") |>
  annotateConsensusClusters(gff)

# Consider removeSingletons = T, keepSingletonsAbove = ??
ce_no <- ce[, ! ce$SLfound] |>
  aggregateTagClusters() |>
  cumulativeCTSSdistribution(clusters = "consensusClusters") |>
  quantilePositions(clusters = "consensusClusters") |>
  annotateConsensusClusters(gff)
```

The clusters for the trans-spliced reads are short and contain most of the reads.

```{r}
x <- consensusClustersGR(ce_SL)
(100 - ce_SL$outOfClusters / ce_SL$librarySizes) |> round(3)
# Again, the distribution of scores is bimodal, but this time it is because of males
hist(log10(decode(score(x))), br = 100)
consensusClustersGR(ce_SL, 1) |> score() |> decode() |> log10() |> hist(100)
consensusClustersGR(ce_SL, 3) |> score() |> decode() |> log10() |> hist(100)
plotInterquantileWidth(ce_SL, clusters = "consensusClusters", tpmThreshold = 3, qLow = 0.1, qUp = 0.9)
```

The clusters for transcription start reads are broader and miss ~ 10 % of the data.

```{r}
consensusClustersGR(ce_no)
ce_no$outOfClusters / ce_no$librarySizes
```

# Export the CTSS data

Produce one file per sample, containing the unclustered nucleotide-resolution
CAGE data in BED format.  These files are lighter than BAM files and can be
uploaded to ZENBU or re-loaded in _CAGEr_ by collaborators.  What BAM files can
do but "CTSS" BED can not is to show the area covered by the read pair, as
well as the mismatches between reads and the genome.

```{r}
trks <- exportToTrack(ce, oneTrack = FALSE)
for (n in seq_along(trks)) {
  name <- sampleLabels(ce)[n]
  rtracklayer::export.bed(trks[n], paste0(name, ".ctss.bed.gz"))
}

trks <- exportToTrack(ce, oneTrack = FALSE)
for (n in seq_along(trks)) {
  name <- sampleLabels(ce)[n]
  rtracklayer::export.bed(trks[n], paste0(name, ".ctss.bed.gz"))
}
# Export to BigWig if you would like to display in IGV.
for (n in seq_along(trks)) {
  name <- sampleLabels(ce)[n]
  trkL <- split(trks[[n]], strand(trks[[n]]), drop = TRUE)
  trkL[['+']]@trackLine@description <- paste(name, " plus")
  trkL[['-']]@trackLine@description <- paste(name, " plus")
  rtracklayer::export.bw(trkL[['+']], paste0(name, ".plus.bw"))
  rtracklayer::export.bw(trkL[['-']], paste0(name, ".minus.bw"))
}
```

## Upload to ZENBU

With the custom function below, a ZENBU upload file is created.  It is a
tab-separated table containing the path to the file, the sample name, the long
description and a space-separated list of metadata (like in GFF files).

The upload fingerprint is any string that will allow to select at once all
files uploaded in this round, in order to clean up ZENBU in case they become
obsolete because of defect or update.

```{r}
UploadFingerPrint <- "Uploaded on 2023070501."

.ZENBU_filelist <- function(DF, file = NULL, suffix, prefix = NULL) {
  DF_sub <- DF
  DF_sub$sampleLabels <- DF_sub$inputFiles <- DF_sub$inputFilesType <- DF_sub$Description <- NULL
  if(is.null(DF$Description)) DF$Description <- ""
  out <- data.frame(path = paste(DF$sampleLabels|>unname(), suffix, sep = "."),
                    name = DF$sampleLabels|>unname(),
                    desc = paste(DF$Description, UploadFingerPrint))
  out$meta <- sapply(1:nrow(DF_sub), \(n) {
    paste(colnames(DF_sub), sapply(DF_sub[n,,drop =TRUE], unname), sep = "=", collapse = ";")
  })
  if(is.null(file)) {
    return(out)
  } else {
    write.table(out, file, quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)
  }
  invisible(out)
}

.ZENBU_filelist(colData(ce), "ZENBU_upload_CTSS_bed.tsv", suffix = "ctss.bed")
```

```
# ml use /apps/unit/LuscombeU/.modulefiles
# ml ZENBU

# zenbu_upload -url https://fantom.gsc.riken.jp/zenbu/ -filelist ZENBU_upload_CTSS_bed.tsv -assembly Oidioi_Bar2_p4.Flye -score_exp raw -collab orXQCELWOZfm7KLNMMpPdD
```

# Export Consensus clusters

```{r}
cctrack_SL <- exportToTrack(ce_SL, "consensusClusters", qLow = 0.1, qUp = 0.9)
cctrack_SL@trackLine@description <- "CAGE Consensus Clusters for trans splicing sites"
cctrack_SL@trackLine@name <- "SL"
# Flat AG
cctrack_SL$itemRgb <- ifelse(flagByUpstreamSequences(rowRanges(consensusClustersSE(ce_SL))$dominant_ctss, "AG"), "black", "grey")

cctrack_SL[cctrack_SL$itemRgb == "black"] |> score() |> decode() |> log10() |> hist(br=100)
cctrack_SL[cctrack_SL$itemRgb == "grey"]  |> score() |> decode() |> log10() |> hist(br=100)


cctrack_no <- CC_to_track(ce_no)

rtracklayer::export.bed(cctrack_SL, "clusters_SL.bed")
rtracklayer::export.bed(cctrack_no, "clusters_no.bed")
```

```
zenbu_upload -url https://fantom.gsc.riken.jp/zenbu/ -file clusters_SL.bed -name ConsensusClustersSL -desc 'Consensus Clusters for trans-splicing CAGE data. Uploaded on 2023012701.' -assembly Oidioi_Bar2_p4.Flye -collab orXQCELWOZfm7KLNMMpPdD
zenbu_upload -url https://fantom.gsc.riken.jp/zenbu/ -file clusters_no.bed -name ConsensusClustersNoSL -desc 'Consensus Clusters for transription start CAGE data. Uploaded on 2023012701.' -assembly Oidioi_Bar2_p4.Flye -collab orXQCELWOZfm7KLNMMpPdD
```

# Export the _CAGEexp_ object.

```{r}
saveRDS(ce,       "ce.rds")
saveRDS(ce_SL, "ce_SL.rds")
saveRDS(ce_no, "ce_no.rds")
```

# Session information

```{r sessionInfo}
sessionInfo()
```

---
title: "CAGE Oikopleura"
author: "Charles Plessy"
date: "19/07/2023"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load the CAGE data from BAM files.

BAM files produced by HiSat2 are loaded in paired-end mode.  Sample names are
parsed from the file names.

## Setup

```{r setup}
BSgenomeToUse <- "BSgenome.Oidioi.OIST.Bar2.p4"
if(isFALSE(requireNamespace(BSgenomeToUse, quietly = TRUE)))
  install.packages(BSgenomeToUse,
                   repos="https://oist.github.io/plessy_oikgenomes_drat/")
pathToBamFiles <- "hisat2"
```

## Load BAM files

We use _CAGEr_ to load BAM files and turn the tag alignments into
single-nucleotide positions called _CTSS_ (CAGE Transcription Start Sites).
For trans-spliced sites, it conveniently matches the same acronym.

```{r load_BAM_files}
library("CAGEr")
library("ggplot2")
library("patchwork")

pathsToInputFiles <- list.files(pathToBamFiles,
                                pattern = "*.sorted.bam$",
                                full.names = TRUE)
sampleLabels <- make.names(sub( ".sorted.bam", "", basename(pathsToInputFiles)))
ce <-
  CAGEexp( metadata = list(genomeName = BSgenomeToUse)
         , colData  = DataFrame( inputFiles     = pathsToInputFiles
                               , sampleLabels   = sampleLabels
                               , inputFilesType = "bamPairedEnd"
                               , row.names      = sampleLabels))

ce <- getCTSS(ce, useMulticore = TRUE, nrCores = 3, correctSystematicG=FALSE, removeFirstG=FALSE)
```

# Prepare metadata

## Polish sample data

Extra information is parsed from the file names, and is used to prepare short
descriptions in plain English.

```{r}
librarySizes(ce) # This is only the mapped ones
colData(ce)
ce$SLfound  <- grepl("SL", sampleLabels(ce))
ce$SLfactor <- ce$SLfound |> factor(labels = c("SL not found", "SL found"))
ce$sampleType <- "Adult"
ce$sampleType[grepl("Rep", sampleLabels(ce))] <- "Embry"
ce$RNA <- sampleLabels(ce) |> sub(pat = "_SL.*|_no.*", rep = "") |> sub(pat = "^X", rep = "") |> unname()
ce$Description <-
  paste0("Oikopleura dioica (Barcelona) CAGE library prepared by DNAFORM in 2022—23 from the RNA sample “",
       ce$RNA, "”. ",
       ifelse(ce$SLfound, "A splice leader sequence was found and removed. ",
              "No splice leader sequence was found. "),
       "The reads where then aligned with HISAT2 using the nf-core RNA-seq pipeline version 3.4.")

colData(ce)
```

## Get counts of unmapped reads

```{r hisat}
hs <- read.table(head = TRUE, "../AlignWithRNAseqPipelinePE/results/multiqc/hisat2/multiqc_data/multiqc_hisat2.txt")
rownames(hs) <- make.names(hs$Sample)
hs <- hs[sampleLabels(ce),]
# Apparently, multimapped reads have been removed by the pipeline.
all(librarySizes(ce) == hs$paired_aligned_one)
ce$paired_aligned_one   <- hs$paired_aligned_one
ce$paired_aligned_multi <- hs$paired_aligned_multi
ce$paired_total         <- hs$paired_total
```

```{r otherqc}
qc <- read.table(head = TRUE, sep = '\t', "../AlignWithRNAseqPipelinePE/results/multiqc/hisat2/multiqc_data/multiqc_general_stats.txt")
rownames(qc) <- make.names(qc$Sample)
qc2 <- qc[paste0(sampleLabels(ce), "_2"),]
ce$realLibrarySizes <- qc2$FastQC..raw._mqc.generalstats.fastqc_raw.total_sequences
ce$extracted    <- qc2$FastQC..trimmed._mqc.generalstats.fastqc_trimmed.total_sequences
```

```{r rrna}
# Unfortunately we have only the sum of the extraction for both reads,
# But we need the results in number of pairs.
# rrna <- read.table(head = TRUE, sep = '\t', "../AlignWithRNAseqPipelinePE/results/multiqc/hisat2/multiqc_data/multiqc_sortmerna.txt")
# rownames(rrna) <- make.names(rrna$Sample)
# ce$rdna <- rrna[paste0(sampleLabels(ce), "_2"), "rRNA"]

# Good enough approximate:
ce$rdna <- ce$extracted - ce$paired_total
```

# Pipeline QC

 - Almost all reads were properly extracted (non-Discarded).
 - The proportion on unmapped reads is moderate.
 - We do not find rRNA reads in the trans-spliced RNAs.
 - The proportion of trans-spliced reads is noticeably smaller in the male sample.

```{r pipeline_QC}
msScope_nfcore_rnaseq <- function(libs) {
  CAGEr:::.checkLibsDataFrame(libs, c("extracted", "rdna",
                                      "paired_total", "paired_aligned_multi", "paired_aligned_one",
                                      "realLibrarySizes"))
  libs$rDNA           <- libs$rdna
  libs$Unmapped       <- libs$paired_total - libs$paired_aligned_one - libs$paired_aligned_multi
  libs$Multimapped    <- libs$paired_aligned_multi
  libs$UniquelyMapped <- libs$paired_aligned_one
  libs$Discarded      <- libs$realLibrarySizes - libs$extracted
  list(libs = libs, columns = c("Discarded","rDNA", "Unmapped", "Multimapped", "UniquelyMapped"), total = libs$realLibrarySizes)
}
plotAnnot(ce, msScope_nfcore_rnaseq, group = "RNA", facet = "SLfactor", norm = FALSE) +
  ylab("Number of tags processed") + xlab("Sample name") +
  ggtitle("QC report of CAGE library alignment",
          sub = "The splice leader sequence was detected and removed before alignment.")
```

# Annotation QC

As of January 2023, the gene models were produced by AUGUSTUS, and begin
at the translation start site.  The plots below should therefore be interpreted
with caution.  Nevertheless, they indicate that most of the CAGE reads align
near promoters.

```{r}
gff <- rtracklayer::import("../AlignWithRNAseqPipelinePE/Bar2_p4.gm.gtf")
gff$type <- as.character(gff$type)
gff <- gff[gff$type %in% c("transcript", "intron", "exon")]
gff$gene_name <- gff$gene_id

ce <- annotateCTSS(ce, gff)
colData(ce)[,c("librarySizes", "promoter", "exon", "intron", "unknown")]
colData(ce)[,c("promoter", "exon", "intron", "unknown")] |> as.matrix() |> prop.table(1)  |> round(2)
plotAnnot(ce, "counts", group = "RNA", facet = "SLfactor", normalise = TRUE) +
  ylab("Fraction of tags aligned") +
  xlab("Sample name") +
  ggtitle("Annotation of the aligned tags",
          subtitle = "The promoters are defined as the 1-kb window centered on the transcript start site.")
```

# Correlate expression per chromosome.

This gives a very quick and rough clustering of the samples.

```{r}
ce <- summariseChrExpr(ce)
seqNameTotalsSE(ce) |> assay()
seqNameTotalsSE(ce) |> assay() |> cor(meth="spe") |> pheatmap::pheatmap()
```

# Reverse cumulative distribution of the CTSSes

Distributions of expression values differ strongly between the trans-splicing
sites and the transcription start sites.  We will need to normalise them
separately.

```{r}
ce <- setColors(ce, c("red", "red", "red", "red",
                      "blue", "blue",
                      "pink", "pink", "pink", "pink",
                      "green", "green", "green", "green", "green", "green", "green", "green"))
rangeForSL <- c(1e1, 5e2)
plotReverseCumulatives(ce[,   ce$SLfound], fitInRange = rangeForSL, values = "raw", onePlot = TRUE, main = "SL found")
rangeForTSS <- c(3e1, 3e4)
plotReverseCumulatives(ce[, ! ce$SLfound], fitInRange = rangeForTSS, values = "raw", onePlot = TRUE, main = "SL not found")
#plotReverseCumulatives(ce, fitInRange = rangeForTSS, values = "raw", group = "SLfactor")
```

# Export the CTSS data

Produce one file per sample, containing the unclustered nucleotide-resolution
CAGE data in BED format.  These files are lighter than BAM files and can be
uploaded to ZENBU or re-loaded in _CAGEr_ by collaborators.  What BAM files can
do but "CTSS" BED can not is to show the area covered by the read pair, as
well as the mismatches between reads and the genome.

## Prepare tracks

```{r}
trks <- exportToTrack(ce, oneTrack = FALSE)
for (n in seq_along(trks)) {
  name <- sampleLabels(ce)[n]
  rtracklayer::export.bed(trks[n], paste0(name, ".ctss.bed.gz"))
}

trks <- exportToTrack(ce, oneTrack = FALSE)
for (n in seq_along(trks)) {
  name <- sampleLabels(ce)[n]
  rtracklayer::export.bed(trks[n], paste0(name, ".ctss.bed.gz"))
}
# Export to BigWig if you would like to display in IGV.
for (n in seq_along(trks)) {
  name <- sampleLabels(ce)[n]
  trkL <- split(trks[[n]], strand(trks[[n]]), drop = TRUE)
  trkL[['+']]@trackLine@description <- paste(name, " plus")
  trkL[['-']]@trackLine@description <- paste(name, " plus")
  rtracklayer::export.bw(trkL[['+']], paste0(name, ".plus.bw"))
  rtracklayer::export.bw(trkL[['-']], paste0(name, ".minus.bw"))
}
```

## Upload to ZENBU

With the custom function below, a ZENBU upload file is created.  It is a
tab-separated table containing the path to the file, the sample name, the long
description and a space-separated list of metadata (like in GFF files).

The upload fingerprint is any string that will allow to select at once all
files uploaded in this round, in order to clean up ZENBU in case they become
obsolete because of defect or update.

```{r}
UploadFingerPrint <- "Uploaded on 2023070501."

.ZENBU_filelist <- function(DF, file = NULL, suffix, prefix = NULL) {
  DF_sub <- DF
  DF_sub$sampleLabels <- DF_sub$inputFiles <- DF_sub$inputFilesType <- DF_sub$Description <- NULL
  if(is.null(DF$Description)) DF$Description <- ""
  out <- data.frame(path = paste(DF$sampleLabels|>unname(), suffix, sep = "."),
                    name = DF$sampleLabels|>unname(),
                    desc = paste(DF$Description, UploadFingerPrint))
  out$meta <- sapply(1:nrow(DF_sub), \(n) {
    paste(colnames(DF_sub), sapply(DF_sub[n,,drop =TRUE], unname), sep = "=", collapse = ";")
  })
  if(is.null(file)) {
    return(out)
  } else {
    write.table(out, file, quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)
  }
  invisible(out)
}

.ZENBU_filelist(colData(ce), "ZENBU_upload_CTSS_bed.tsv", suffix = "ctss.bed")
```

```
# ml use /apps/unit/LuscombeU/.modulefiles
# ml ZENBU

# zenbu_upload -url https://fantom.gsc.riken.jp/zenbu/ -filelist ZENBU_upload_CTSS_bed.tsv -assembly Oidioi_Bar2_p4.Flye -score_exp raw -collab orXQCELWOZfm7KLNMMpPdD
```

# Split the objects and normalise

## TPM for the trans-splicing sites

The expression values SL peaks do not follow a power law distribution.

```{r}
ce_SL <- ce[,   ce$SLfound] |>
  resetCAGEexp() |>
  normalizeTagCount(method = "simpleTpm") |>
  annotateCTSS(gff)
plotReverseCumulatives(ce_SL, fitInRange = NULL, values = "normalized", onePlot = TRUE, main = "SL found")
p1 <- plotReverseCumulatives(ce_SL, fitInRange = NULL, values = "raw") +
  ggtitle("SL found", sub="Before normalisation") + theme_bw()
p2 <- plotReverseCumulatives(ce_SL, fitInRange = NULL, values = "normalized") +
  ggtitle("SL found", sub="TPM normalised") + theme_bw()
(p1 | p2) + plot_layout(guides = 'collect')

# Explore properties of low-expressed CTSS
CTSScoordinatesGR(ce_SL)$CTSS_expr_range <- CAGEr:::rowSums.RleDataFrame(CTSSnormalizedTpmDF(ce_SL)) |> decode() |> cut(c(0, 10, 1000, 1e6))
summary(CTSScoordinatesGR(ce_SL)$CTSS_expr_range)
plotAnnot_CTSS <- function(x, gff, ...) {
  # plot percent of clusters, not percent of sum of expression of clusters
  x <- resetCAGEexp(x)
  DF <- lapply(assay(x), \(y) Rle(as.numeric(y > 0))) |> DataFrame()
  assay(CTSStagCountSE(x)) <- DF
  x <- annotateCTSS(x, gff)
  x$librarySizes <- sapply(assay(x),sum)
  plotAnnot(x, "counts")
}

# A lot of the low-expression ones are still near promoters, but pay attention
# that "promoters" are 1-kb windows here.
CTSScoordinatesGR(ce_SL)$CTSS_expr_range <- CAGEr:::rowSums.RleDataFrame(CTSSnormalizedTpmDF(ce_SL)) |> decode() |> cut(c(0, 10, 1000, 1e6))
p_10 <- plotAnnot_CTSS(ce_SL[CTSScoordinatesGR(ce_SL)$CTSS_expr_range == "(0,10]", ] , gff)
p_1000 <- plotAnnot_CTSS(ce_SL[CTSScoordinatesGR(ce_SL)$CTSS_expr_range == "(10,1e+03]", ], gff)
p_1000000 <- plotAnnot_CTSS(ce_SL[CTSScoordinatesGR(ce_SL)$CTSS_expr_range == "(1e+03,1e+06]", ], gff)

(p_10 / p_1000 / p_1000000 ) + plot_layout(guides = 'collect')

plotAnnot_CTSS(ce_SL[, ], gff)
```

The male library has a different distribution of CTSS expression values compared
with others.

## Power law for the transcription start sites.

```{r}
ce_no <- ce[, ! ce$SLfound] |> resetCAGEexp()
rangeForTSS <- c(3e1, 3e4)
plotReverseCumulatives(ce_no, fitInRange = rangeForTSS, values = "raw", onePlot = TRUE, main = "SL not found (raw)")
ce_no |> normalizeTagCount(method = "simpleTpm", fitInRange = rangeForTSS) |>
  plotReverseCumulatives(ce_no.tpm, fitInRange = NULL, values = "normalized", onePlot = TRUE, main = "SL not found (TPM normalisation)")
ce_no <- ce_no |> normalizeTagCount(method = "powerLaw", fitInRange = rangeForTSS)
plotReverseCumulatives(ce_no, fitInRange = NULL, values = "normalized", onePlot = TRUE, main = "SL not found (power law normalisation")

p1 <- plotReverseCumulatives(ce_no, fitInRange = NULL, values = "raw") +
  ggtitle("No SL", sub="Before normalisation") + theme_bw()
p2 <- plotReverseCumulatives(ce_no, fitInRange = NULL, values = "normalized") +
  ggtitle("No SL", sub="Power-law normalised") + theme_bw()
(p1 | p2) + plot_layout(guides = 'collect')
```

The power law normalisation is more efficient at giving the same distribution
to the libraries, at least on average expression values.  Again, the male
library makes an exception.

# Clustering

## Produce sharp clusters of trans-splicing sites

Try different parameters

```{r try_paraclu}
# Explore a subset of the data
ce_SL |> CTSSnormalizedTpmGR(1)|> head(10000) |>
  paraclu(maxLength = 10L, removeSingletons = TRUE, keepSingletonsAbove = 0) |>
  score() |> decode() |> log10() |> hist()
# The distribution of scores is bimodal, with a valley around 1.
ce_SL |> CTSSnormalizedTpmGR(1)|> head(1000) |> paraclu(maxLength = 10L, removeSingletons = TRUE, keepSingletonsAbove = 1) |> length()
ce_SL |> CTSSnormalizedTpmGR(1)|> head(1000) |> paraclu(maxLength = 20L, removeSingletons = TRUE, keepSingletonsAbove = 1) |> length()
ce_SL |> CTSSnormalizedTpmGR(1)|> head(1000) |> paraclu(maxLength = 50L, removeSingletons = TRUE, keepSingletonsAbove = 1) |> length()
ce_SL |> CTSSnormalizedTpmGR(1)|> head(1000) |> paraclu(maxLength = 200L, removeSingletons = TRUE, keepSingletonsAbove = 1) |> length()
ce_SL |> CTSSnormalizedTpmGR(1)|> head(1000) |> paraclu(maxLength = 500L, removeSingletons = TRUE, keepSingletonsAbove = 1) |> length()
# There is not much penalty keeping the peaks narrow.
```

## Produce sharp clusters of trans-splicing sites

```{r ce_SL_paraclu}
ce_SL <- ce_SL |> clusterCTSS( method = "paraclu"
                             , nrPassThreshold = 1 # Default.  We do not have replicates for all time points
                             , threshold = 1   # See above.  Note that it allows low-score CTSS supported in other samples.
                             , maxLength = 10L # Keep them sharp
                             , useMulticore = TRUE # Deigo
                             , nrCores = 8)    |>    # Yay !
                  cumulativeCTSSdistribution() |>
                  quantilePositions()
plotInterquantileWidth(ce_SL, clusters = "tagClusters", tpmThreshold = 3, qLow = 0.1, qUp = 0.9) + ggplot2::theme_bw()
tcs <- tagClustersGR(ce_SL)
tcs@metadata$colData <- colData(ce_SL)
plotReverseCumulatives(tcs)
f <- function(name, tc) {
  tc[[name]] |> as.data.frame() |>
    dplyr::mutate(sampleName = name)
}
lapply(names(tcs), f, tcs) |> do.call(what = rbind) |> ggplot() +
  aes(x = score, fill = sampleName) +
  geom_histogram(bins = 100) +
  scale_x_log10() + facet_wrap(~sampleName) + theme_bw()

tagClustersGR(ce_SL) |> sapply(length)
# Not super useful plot: most SL TCs are CTSSes anyway.
tagClustersGR(ce_SL, 1) |> score() |> decode() |> CAGEr:::.plotReverseCumulative(title=n)
for (n in 2:8) {
tagClustersGR(ce_SL, n) |> score() |> decode() |> CAGEr:::.plotReverseCumulative(title=n, add = TRUE)
}

(tagClustersGR(ce_SL, 1) |> score() > 1) |> sum()
```

## Cluster clusters of transcription start sites.
  
```{r ce_no_paraclu}
# Can't try paraclu at low threshold, but at high threshold it discards too much. (some clusters become single-peak)
# ce_no <- ce_no |> clusterCTSS( method = "paraclu"  # Not enough memory for paraclu?  Mabye because running in parallel?
#                              , nrPassThreshold = 1 # Default.  We do not have replicates for all time points
#                              , threshold = 10, thresholdIsTpm = TRUE  # At least 10 TPM in one library
#                              , maxLength = 200 # Not the default
#                              , useMulticore = TRUE # Deigo
#                              , nrCores = 2)    |>    # Memory-hungry…
#                   cumulativeCTSSdistribution() |>
#                   quantilePositions()
ce_no <- ce_no |> clusterCTSS( method = "distclu"  
                             , nrPassThreshold = 1 # Default.  We do not have replicates for all time points
                             , threshold = 1, thresholdIsTpm = TRUE)    |>  
                  cumulativeCTSSdistribution() |>
                  quantilePositions()
plotInterquantileWidth(ce_no, clusters = "tagClusters", tpmThreshold = 3, qLow = 0.1, qUp = 0.9) + ggplot2::theme_bw()

tcs <- tagClustersGR(ce_no)
tcs@metadata$colData <- colData(ce_no)
plotReverseCumulatives(tcs)
f <- function(name, tc) {
  tc[[name]] |> as.data.frame() |>
    dplyr::mutate(sampleName = name)
}
lapply(names(tcs), f, tcs) |> do.call(what = rbind) |> ggplot() +
  aes(x = score, fill = sampleName) +
  geom_histogram(bins = 100) +
  scale_x_log10() + facet_wrap(~sampleName) + theme_bw()

tagClustersGR(ce_no) |> sapply(length)
# Not super useful plot: most SL TCs are CTSSes anyway.
tagClustersGR(ce_no, 1) |> score() |> decode() |> CAGEr:::.plotReverseCumulative(title=n)
for (n in 2:8) {
tagClustersGR(ce_no, n) |> score() |> decode() |> CAGEr:::.plotReverseCumulative(title=n, add = TRUE)
}
```

# Aggregate the CAGE tags

```{r}
# First I ran with a threshold of 1, but it captured a lot of ectopic trans-splicing
# at splice junctions, which we do not want to use for updating annotation and
# defining operons.
ce_SL <- ce_SL |> 
  aggregateTagClusters(maxDist = 10L, tpmThreshold = 10, excludeSignalBelowThreshold = FALSE) |>  # See also the score distribution
  cumulativeCTSSdistribution(clusters = "consensusClusters") |>
  quantilePositions(clusters = "consensusClusters") |>
  annotateConsensusClusters(gff)

# Consider removeSingletons = T, keepSingletonsAbove = ??
ce_no <- ce_no |>
  aggregateTagClusters() |>
  cumulativeCTSSdistribution(clusters = "consensusClusters") |>
  quantilePositions(clusters = "consensusClusters") |>
  annotateConsensusClusters(gff)
```

The clusters for the trans-spliced reads are short and contain most of the reads.

```{r}
x <- consensusClustersGR(ce_SL)
(100 - ce_SL$outOfClusters / ce_SL$librarySizes) |> round(3)
# Again, the distribution of scores is bimodal
hist(log10(decode(score(x))), br = 100)
consensusClustersGR(ce_SL, 1) |> score() |> decode() |> log10() |> hist(100)
consensusClustersGR(ce_SL, 3) |> score() |> decode() |> log10() |> hist(100)
plotInterquantileWidth(ce_SL, clusters = "consensusClusters", tpmThreshold = 3, qLow = 0.1, qUp = 0.9)

rowRanges(consensusClustersSE(ce_SL))$normExprTot <- rowSums(consensusClustersSE(ce_SL)|>assay("normalized")) 
rowRanges(consensusClustersSE(ce_SL))$normExprRange <- cut(rowRanges(consensusClustersSE(ce_SL))$normExprTot, c(0, 10, 1000, 1e6))
rowRanges(consensusClustersSE(ce_SL))$normExprRange  |> summary()

```

The clusters for transcription start reads are broader and miss ~ 10 % of the data.

```{r}
(cc_no <- consensusClustersGR(ce_no))
(cc_no_qq <- consensusClustersGR(ce_no, qLow = 0.1, qUp = 0.9, returnInterquantileWidth = TRUE))
(100 - ce_no$outOfClusters / ce_no$librarySizes) |> round(1)
hist(log10(decode(score(cc_no))), br = 100)
consensusClustersGR(ce_no, 1) |> score() |> decode() |> log10() |> hist(100)
consensusClustersGR(ce_no, 3) |> score() |> decode() |> log10() |> hist(100)
plotInterquantileWidth(ce_no, clusters = "consensusClusters", tpmThreshold = 3, qLow = 0.1, qUp = 0.9, xlim = c(10, 1000))  + scale_x_log10()
```

# Export Consensus clusters

## Trans-splicing sites

Paint in grey those that do not have `AG` upstream.

```{r}
cctrack_SL <- exportToTrack(ce_SL, "consensusClusters", qLow = 0.1, qUp = 0.9)
cctrack_SL@trackLine@description <- "CAGE Consensus Clusters for trans splicing sites"
cctrack_SL@trackLine@name <- "SL"
# Flat AG
cctrack_SL$itemRgb <- ifelse(flagByUpstreamSequences(rowRanges(consensusClustersSE(ce_SL))$dominant_ctss, "AG"), "black", "grey")

cctrack_SL[cctrack_SL$itemRgb == "black"] |> score() |> decode() |> log10() |> hist(br=100)
cctrack_SL[cctrack_SL$itemRgb == "grey"]  |> score() |> decode() |> log10() |> hist(br=100)

rtracklayer::export.bed(cctrack_SL, "clusters_SL.bed")
```

```{r}
cctrack_no <- exportToTrack(ce_no, "consensusClusters", qLow = 0.1, qUp = 0.9)
cctrack_no@trackLine@description <- "CAGE Consensus Clusters for transcription start sites"
cctrack_no@trackLine@name <- "TSS"
# Flat the clusters of width 1.
cctrack_no$itemRgb <- ifelse(width(cctrack_no) > 1, "black", "grey")

rtracklayer::export.bed(cctrack_no, "clusters_no.bed")
```

```
zenbu_upload -url https://fantom.gsc.riken.jp/zenbu/ -file clusters_SL.bed -name ConsensusClustersSL -desc 'Consensus Clusters for trans-splicing CAGE data. Uploaded on 2023012701.' -assembly Oidioi_Bar2_p4.Flye -collab orXQCELWOZfm7KLNMMpPdD
zenbu_upload -url https://fantom.gsc.riken.jp/zenbu/ -file clusters_no.bed -name ConsensusClustersNoSL -desc 'Consensus Clusters for transription start CAGE data. Uploaded on 2023012701.' -assembly Oidioi_Bar2_p4.Flye -collab orXQCELWOZfm7KLNMMpPdD
```

# Export the _CAGEexp_ object.

```{r}
saveRDS(ce,       "ce.rds")
saveRDS(ce_SL, "ce_SL.rds")
saveRDS(ce_no, "ce_no.rds")
```

# AG motifs

```{r AG_motifs}

TSSlogo(cctrack_SL[cctrack_SL$itemRgb == "black"], 40, 20)
TSSlogo(cctrack_SL[cctrack_SL$itemRgb == "black"], 16, 16) # Very similar to Danks 2015 !!
TSSlogo(cctrack_SL[cctrack_SL$itemRgb == "grey"], 40, 20)
TSSlogo(cctrack_SL[cctrack_SL$itemRgb == "grey"], 16, 16)

seqLogo_GR(cctrack_no, 35, 15)

cctrack_SL$dominant_ctss |> promoters(2,0) |> getSeq (x = BSgenome::getBSgenome('Bar2.p4')) |> table() |> prop.table() |> tibble::as_tibble() |> ggplot() + aes(y = upstreamSeq, x = n) + geom_point() + scale_x_continuous("frequency", labels = scales::label_percent())
```

# Sharp and broad promoters

```{r}
TSSlogo(cc_no, 30)
TSSlogo(cc_no[width(cc_no)  > 25], 30) + ggtitle("width > 25")
TSSlogo(cc_no[width(cc_no) <= 25], 30) + ggtitle("width <= 25")


hist(cctrack_no$tpm.dominant_ctss |> decode() / score(cctrack_no) |> decode())
cctrack_no[cctrack_no$tpm.dominant_ctss |> decode() / score(cctrack_no) |> decode() > 0.5] |> seqLogo_GR(40,10)
cctrack_no[cctrack_no$tpm.dominant_ctss |> decode() / score(cctrack_no) |> decode() < 0.5] |> seqLogo_GR(40,10)
```

# Enhancers

```{r enhancers}
ce_no <- ce_no |> quickEnhancers()
enh_trk <- ce_no[["enhancers"]] |> rowRanges() |> exportToTrack()
rtracklayer::export.bed(enh_trk, "enhancers.bed")
enh_trk |> TSSlogo()
enh_trk |> plyranges::mutate(dominant_ctss = GRanges(seqnames, thick, seqinfo = seqinfo(enh_trk))) |> seqLogo_GR(50,50)
rtracklayer::export.bed(enh_trk, "enhancers.bed")
```

# seqArchR

```{r seqArchR_SL}
# Load seqArchR
library(seqArchR)
library(Biostrings) |> suppressPackageStartupMessages()
set.seed(1234)
inputSeqsRaw <- cctrack_SL$dominant_ctss |> promoters(40,40) |> trim() |> getSeq (x = BSgenome::getBSgenome('Bar2.p4')) |> suppressWarnings()
inputSeqsRaw <- inputSeqsRaw[width(inputSeqsRaw) == 80] # remove trimmed sequences
inputSeqsMat <- seqArchR::get_one_hot_encoded_seqs(seqs = inputSeqsRaw, sinuc_or_dinuc = "dinuc")

nSeqs <- length(inputSeqsRaw)
positions <- seq(1, Biostrings::width(inputSeqsRaw[1]))

seqArchR::viz_seqs_acgt_mat(as.character(inputSeqsRaw),  pos_lab = positions - 40)

seqArchRconfig <- seqArchR::set_config(
        parallelize = TRUE,
        n_cores = 4,
        n_runs = 100,
        k_min = 1,
        k_max = 20,
        mod_sel_type = "stability",
        bound = 10^-6,
        chunk_size = 100,
        result_aggl = "ward.D", 
        result_dist = "euclid",
        flags = list(debug = FALSE, time = TRUE, verbose = TRUE,
                     plot = FALSE)
)

seqArchRresult <- seqArchR::seqArchR(config = seqArchRconfig,
                            seqs_ohe_mat = inputSeqsMat,
                            seqs_raw = inputSeqsRaw,
                            seqs_pos = positions,
                            total_itr = 2,
                            set_ocollation = c(TRUE, FALSE))

seqArchR::viz_bas_vec(feat_mat = get_clBasVec_m(seqArchRresult, 1), 
                      ptype = c("heatmap", "seqlogo"), method = "bits", 
                      sinuc_or_dinuc = "dinuc")

seqArchR::viz_bas_vec(feat_mat = get_clBasVec_m(seqArchRresult, 2), 
                      ptype = c("heatmap", "seqlogo"), method = "bits", 
                      sinuc_or_dinuc = "dinuc")


seqArchR::viz_seqs_acgt_mat(seqs_str(seqArchRresult, iter = 1, ord = TRUE),
                                  pos_lab = positions)


seqArchR::viz_seqs_acgt_mat(seqs_str(seqArchRresult, iter = 2, ord = TRUE),
                                  pos_lab = positions)
```


```{r seqArchR_TSS}
# Load seqArchR
library(seqArchR)
library(Biostrings) |> suppressPackageStartupMessages()
set.seed(1234)
inputSeqsRaw <- cctrack_no$dominant_ctss |> promoters(40,20) |> trim() |> getSeq (x = BSgenome::getBSgenome('Bar2.p4')) |> suppressWarnings()
inputSeqsRaw <- inputSeqsRaw[width(inputSeqsRaw) == 60] # remove trimmed sequences
inputSeqsMat <- seqArchR::get_one_hot_encoded_seqs(seqs = inputSeqsRaw, sinuc_or_dinuc = "dinuc")

nSeqs <- length(inputSeqsRaw)
positions <- seq(1, Biostrings::width(inputSeqsRaw[1]))

seqArchR::viz_seqs_acgt_mat(as.character(inputSeqsRaw),  pos_lab = positions - 100)

seqArchRconfig <- seqArchR::set_config(
        parallelize = TRUE,
        n_cores = 2,
        n_runs = 100,
        k_min = 1,
        k_max = 50,
        mod_sel_type = "stability",
        bound = 10^-6,
        chunk_size = 1000,
        result_aggl = "ward.D", 
        result_dist = "euclid",
        flags = list(debug = FALSE, time = TRUE, verbose = TRUE,
                     plot = FALSE)
)

seqArchRresult <- seqArchR::seqArchR(config = seqArchRconfig,
                            seqs_ohe_mat = inputSeqsMat,
                            seqs_raw = inputSeqsRaw,
                            seqs_pos = positions,
                            total_itr = 5,
                            set_ocollation = c(TRUE, TRUE, TRUE, TRUE, TRUE))

  seqArchR::viz_bas_vec(feat_mat = get_clBasVec_m(seqArchRresult, 1), 
                      ptype = c("heatmap", "seqlogo"), method = "bits", 
                      sinuc_or_dinuc = "dinuc")

seqArchR::viz_bas_vec(feat_mat = get_clBasVec_m(seqArchRresult, 2), 
                      ptype = "seqlogo", method = "bits", 
                      sinuc_or_dinuc = "dinuc")


seqArchR::viz_seqs_acgt_mat(seqs_str(seqArchRresult, iter = 1, ord = TRUE),
                                  pos_lab = positions)


seqArchR::viz_seqs_acgt_mat(seqs_str(seqArchRresult, iter = 3, ord = TRUE),
                                  pos_lab = positions)
```


# Hanabi !

```{r hanabi_plots}
plot(hanabi(CTSStagCountDF(ce_SL)))
plot(hanabi(CTSStagCountDF(ce_no)))

plot(hanabi(consensusClustersSE(ce_SL)|> assay()))
plot(hanabi(consensusClustersSE(ce_no)|> assay()))

```

# Session information

```{r sessionInfo}
sessionInfo()
```